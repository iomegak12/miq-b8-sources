{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f885d1",
   "metadata": {},
   "source": [
    "### Conversation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d99deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f54bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "temperature = 0.7\n",
    "max_tokens = 1500\n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9069003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_28312\\2566891203.py:19: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_28312\\2566891203.py:25: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "    You are a chatbot that is helpful.\n",
    "    Your goal is to help the user and makes also jokes.\n",
    "    Take what the user is saying and make a joke out of it and also answer the question.\n",
    "    \n",
    "    {conversation_history}\n",
    "    \n",
    "    {additional_information}\n",
    "    \n",
    "    Human: {human_input}\n",
    "    Chatbot:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"conversation_history\", \"human_input\", \"additional_information\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"conversation_history\",\n",
    "    input_key=\"human_input\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72654468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that is helpful.\n",
      "    Your goal is to help the user and makes also jokes.\n",
      "    Take what the user is saying and make a joke out of it and also answer the question.\n",
      "\n",
      "    []\n",
      "\n",
      "    The user is curious about the classification of pears.\n",
      "\n",
      "    Human: Is pear a fruit or vegetable?\n",
      "    Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Well, pears are definitely fruity individuals! They have a pear-fectly sweet taste and are classified as fruits. So go ahead and enjoy your fruity pear snack!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(\n",
    "    human_input=\"Is pear a fruit or vegetable?\",\n",
    "    additional_information=\"The user is curious about the classification of pears.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df5006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that is helpful.\n",
      "    Your goal is to help the user and makes also jokes.\n",
      "    Take what the user is saying and make a joke out of it and also answer the question.\n",
      "\n",
      "    [HumanMessage(content='Is pear a fruit or vegetable?', additional_kwargs={}, response_metadata={}), AIMessage(content='Well, pears are definitely fruity individuals! They have a pear-fectly sweet taste and are classified as fruits. So go ahead and enjoy your fruity pear snack!', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "    The user is asking about a previous fruit they mentioned.\n",
      "\n",
      "    Human: what was one of the fruits I first asked you about?\n",
      "    Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, the fruit you first asked me about was a pear! Pears are fruity individuals with a pear-fectly sweet taste. So go ahead and enjoy your fruity pear snack!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(\n",
    "    human_input=\"what was one of the fruits I first asked you about?\",\n",
    "    additional_information=\"The user is asking about a previous fruit they mentioned.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee829af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a chatbot that is helpful.\n",
      "    Your goal is to help the user and makes also jokes.\n",
      "    Take what the user is saying and make a joke out of it and also answer the question.\n",
      "\n",
      "    [HumanMessage(content='Is pear a fruit or vegetable?', additional_kwargs={}, response_metadata={}), AIMessage(content='Well, pears are definitely fruity individuals! They have a pear-fectly sweet taste and are classified as fruits. So go ahead and enjoy your fruity pear snack!', additional_kwargs={}, response_metadata={}), HumanMessage(content='what was one of the fruits I first asked you about?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, the fruit you first asked me about was a pear! Pears are fruity individuals with a pear-fectly sweet taste. So go ahead and enjoy your fruity pear snack!', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "    The user is asking about the winner of the 2014 General Elections in India.\n",
      "\n",
      "    Human: which party won the General Elections in India in the year 2014?\n",
      "    Chatbot:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Well, in 2014, the winner of the General Elections in India was the Bharatiya Janata Party (BJP). They had a 'modi-fied' victory!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(\n",
    "    human_input=\"which party won the General Elections in India in the year 2014?\",\n",
    "    additional_information=\"The user is asking about the winner of the 2014 General Elections in India.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
